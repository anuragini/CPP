{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCBlbF4AW2MUy5vVm2lPc7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anuragini/CPP/blob/master/HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fbS2t8YlCny",
        "outputId": "3f059015-b84d-4a3d-daba-89b0d0ba48dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  326k  100  326k    0     0   642k      0 --:--:-- --:--:-- --:--:--  644k\n",
            "Archive:  homework4.zip\n",
            "  inflating: README.md               \n",
            "  inflating: requirements.txt        \n",
            "  inflating: bundle.py               \n",
            "  inflating: homework/__init__.py    \n",
            "  inflating: grader/__main__.py      \n",
            "  inflating: grader/grader.py        \n",
            "  inflating: grader/metrics.py       \n",
            "  inflating: grader/tests.py         \n",
            "  inflating: grader/datasets/road_dataset.py  \n",
            "  inflating: grader/datasets/road_transforms.py  \n",
            "  inflating: grader/datasets/road_utils.py  \n",
            "  inflating: grader/supertux_utils/evaluate.py  \n",
            "  inflating: grader/supertux_utils/video_visualization.py  \n",
            "  inflating: homework/supertux_utils/evaluate.py  \n",
            "  inflating: homework/supertux_utils/video_visualization.py  \n",
            "  inflating: homework/models.py      \n",
            "  inflating: homework/visualization.py  \n",
            "  inflating: homework/metrics.py     \n",
            "  inflating: homework/datasets/road_dataset.py  \n",
            "  inflating: homework/datasets/road_transforms.py  \n",
            "  inflating: homework/datasets/road_utils.py  \n",
            "  inflating: homework/train_planner.py  \n",
            "  inflating: assets/perceiver_architecture.png  \n",
            "  inflating: assets/perceiver_io.png  \n",
            "  inflating: assets/sample.png       \n"
          ]
        }
      ],
      "source": [
        "!curl -O https://www.cs.utexas.edu/~bzhou/dl_class/homework4.zip\n",
        "!unzip -o homework4.zip\n",
        "!rm homework4.zip\n",
        "!curl -s -L https://www.cs.utexas.edu/~bzhou/dl_class/drive_data.zip -o ./drive_data.zip && unzip -qo drive_data.zip\n",
        "# refreshes python imports automatically when you edit the source file\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PySuperTuxKartData\n",
        "!pip install PySuperTuxKart --index-url=https://www.cs.utexas.edu/~bzhou/dl_class/pystk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsyvc1hKllC5",
        "outputId": "4f60d44e-5857-4190-f1d2-52ae0635c8b1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySuperTuxKartData\n",
            "  Using cached PySuperTuxKartData-1.0.0.tar.gz (2.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from PySuperTuxKartData) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData) (2024.8.30)\n",
            "Building wheels for collected packages: PySuperTuxKartData\n",
            "  Building wheel for PySuperTuxKartData (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PySuperTuxKartData: filename=PySuperTuxKartData-1.0.0-py3-none-any.whl size=620700373 sha256=c08fb8ce8a0332b705c8c03726b6489a947ffeea4da235666079e64119032a91\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/da/db/107e5e579034a950bc34417909d989352cd89aa65988af479f\n",
            "Successfully built PySuperTuxKartData\n",
            "Installing collected packages: PySuperTuxKartData\n",
            "Successfully installed PySuperTuxKartData-1.0.0\n",
            "Looking in indexes: https://www.cs.utexas.edu/~bzhou/dl_class/pystk\n",
            "Collecting PySuperTuxKart\n",
            "  Downloading https://www.cs.utexas.edu/~bzhou/dl_class/pystk/pysupertuxkart/PySuperTuxKart-1.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PySuperTuxKartData in /usr/local/lib/python3.10/dist-packages (from PySuperTuxKart) (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from PySuperTuxKartData->PySuperTuxKart) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->PySuperTuxKartData->PySuperTuxKart) (2024.8.30)\n",
            "Installing collected packages: PySuperTuxKart\n",
            "Successfully installed PySuperTuxKart-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.train_mlp --model_name mlp_planner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loRa_aT3sxV3",
        "outputId": "9a2c5d04-ad0d-45e6-839b-220d33e7286f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-12 04:51:42.630714: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-12 04:51:42.659961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-12 04:51:42.666970: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-12 04:51:42.680735: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-12 04:51:43.733055: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loaded 8000 samples from 16 episodes\n",
            "Loaded 2000 samples from 4 episodes\n",
            "Epoch  1 / 50: train_acc=0.0001 val_acc=0.0000\n",
            "Epoch 10 / 50: train_acc=0.0002 val_acc=0.0000\n",
            "Epoch 20 / 50: train_acc=0.0002 val_acc=0.0000\n",
            "Epoch 30 / 50: train_acc=0.0003 val_acc=0.0000\n",
            "Epoch 40 / 50: train_acc=0.0002 val_acc=0.0000\n",
            "Epoch 50 / 50: train_acc=0.0002 val_acc=0.0000\n",
            "Model saved to logs/mlp_planner_1112_045146/mlp_planner.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.train_cnn --model_name cnn_planner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8Nbocirr5n2",
        "outputId": "b4e7a744-3474-428c-9033-dacb290f5193"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-12 05:00:55.656051: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-11-12 05:00:55.676050: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-11-12 05:00:55.682067: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-11-12 05:00:55.697206: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-11-12 05:00:56.773581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loaded 8000 samples from 16 episodes\n",
            "Loaded 2000 samples from 4 episodes\n",
            "Epoch 1/10, train_loss=1.1553, val_loss=0.4912\n",
            "Epoch 2/10, train_loss=0.9554, val_loss=0.5181\n",
            "Epoch 3/10, train_loss=0.5270, val_loss=0.4086\n",
            "Epoch 4/10, train_loss=0.4659, val_loss=0.3790\n",
            "Epoch 5/10, train_loss=0.4362, val_loss=0.4067\n",
            "Epoch 6/10, train_loss=0.4229, val_loss=0.4353\n",
            "Epoch 7/10, train_loss=0.3901, val_loss=0.3516\n",
            "Epoch 8/10, train_loss=0.3771, val_loss=0.3400\n",
            "Epoch 9/10, train_loss=0.3631, val_loss=0.2829\n",
            "Epoch 10/10, train_loss=0.3472, val_loss=0.3492\n",
            "Model saved to logs/cnn_planner_1112_050100/cnn_planner.th\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m grader homework -v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsYLWPQ6wYCJ",
        "outputId": "c3580996-057b-4faa-f5bb-6406fa753b89"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public grader loaded.\n",
            "\u001b[97m[INFO     00:00:003] \u001b[0m\u001b[97mMLP Planner\u001b[0m\n",
            "\u001b[97m[INFO     00:00:285] \u001b[0m\u001b[97m  - Test Output Shape                                  [ 5 / 5 ]\u001b[0m\n",
            "/content/./homework/models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  m.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
            "\u001b[97m[INFO     00:01:703] \u001b[0m\u001b[97m  - Longitudinal Error                                 [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:01:703] \u001b[0m\u001b[33mlongitudinal_error: 0.130\u001b[0m\n",
            "\u001b[97m[INFO     00:01:704] \u001b[0m\u001b[97m  - Longitudinal Error: Extra Credit                   [ 1 / 1 ]\u001b[0m\n",
            "\u001b[97m[INFO     00:01:704] \u001b[0m\u001b[97m  - Lateral Error                                      [ 10 / 10 ]\u001b[0m\n",
            "\u001b[33m[WARNING  00:01:704] \u001b[0m\u001b[33mlateral_error: 0.515\u001b[0m\n",
            "\u001b[97m[INFO     00:01:704] \u001b[0m\u001b[97m  - Lateral Error: Extra Credit                        [ 1 / 1 ]\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YO68eTWCyDgc",
        "outputId": "fd5c0af2-b13f-4e23-8611-59f0580df4bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (2.36.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from imageio) (1.26.4)\n",
            "Requirement already satisfied: pillow>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio) (10.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from datasets.road_dataset import load_data\n",
        "from .models import load_model\n",
        "\n",
        "\n",
        "class Visualizer:\n",
        "    def __init__(self):\n",
        "        fig, axes = plt.subplots(\n",
        "            nrows=1,\n",
        "            ncols=2,\n",
        "            figsize=(10, 4),\n",
        "        )\n",
        "\n",
        "        self.fig = fig\n",
        "        self.axes = axes\n",
        "\n",
        "    def process(\n",
        "        self,\n",
        "        image: torch.Tensor,\n",
        "        track_left: torch.Tensor,\n",
        "        track_right: torch.Tensor,\n",
        "        waypoints: torch.Tensor,\n",
        "        waypoints_mask: torch.Tensor,\n",
        "        pred: torch.Tensor,\n",
        "        batch_idx: int = 0,\n",
        "    ):\n",
        "        track_left = track_left[batch_idx].detach().cpu().numpy()\n",
        "        track_right = track_right[batch_idx].detach().cpu().numpy()\n",
        "        waypoints = waypoints[batch_idx].detach().cpu().numpy()\n",
        "        waypoints_mask = waypoints_mask[batch_idx].detach().cpu().numpy()\n",
        "        pred = pred[batch_idx].detach().cpu().numpy()\n",
        "\n",
        "        _, axes = self.fig, self.axes\n",
        "\n",
        "        for ax in axes:\n",
        "            ax.clear()\n",
        "\n",
        "        axes[0].imshow(image[batch_idx].detach().cpu().numpy().transpose(1, 2, 0))\n",
        "        axes[0].axis(\"off\")\n",
        "\n",
        "        axes[1].plot(track_left[:, 0], track_left[:, 1], \"ro-\")\n",
        "        axes[1].plot(track_right[:, 0], track_right[:, 1], \"bo-\")\n",
        "        axes[1].plot(waypoints[:, 0], waypoints[:, 1], \"g--o\")\n",
        "        # axes[1].plot(pred[:, 0], pred[:, 1], \"c--o\")\n",
        "\n",
        "        axes[1].set_xlim(-10, 10)\n",
        "        axes[1].set_ylim(-5, 15)\n",
        "        axes[1].axis(\"equal\")\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    data_path: str = \"drive_data/val\",\n",
        "    model_name: str = \"mlp_planner\",\n",
        "    device_str: str = \"cuda\",\n",
        "):\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    device = torch.device(device_str)\n",
        "    data = load_data(\n",
        "        data_path,\n",
        "        num_workers=0,\n",
        "        batch_size=1,\n",
        "        shuffle=True,\n",
        "    )\n",
        "\n",
        "    model = load_model(model_name, with_weights=True).to(device)\n",
        "    model.eval()\n",
        "\n",
        "    viz = Visualizer()\n",
        "\n",
        "    for i, batch in enumerate(data):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        image = batch[\"image\"]\n",
        "        track_left = batch[\"track_left\"]\n",
        "        track_right = batch[\"track_right\"]\n",
        "        waypoints = batch[\"waypoints\"]\n",
        "        waypoints_mask = batch[\"waypoints_mask\"]\n",
        "\n",
        "        pred = model(**batch)\n",
        "\n",
        "        viz.process(\n",
        "            image,\n",
        "            track_left,\n",
        "            track_right,\n",
        "            waypoints,\n",
        "            waypoints_mask,\n",
        "            pred,\n",
        "            batch_idx=0,\n",
        "        )\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # just show one sample\n",
        "        break\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    visualize()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "7zKdSxnkxv-r",
        "outputId": "cd722a50-ce7f-49fd-94f2-a5a86012b03b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2ed71fbdd517>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroad_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m homework.supertux_utils.evaluate --model mlp_planner --track lighthouse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZnWkEiqySXB",
        "outputId": "6113f620-d5d0-4219-c58c-23155cd1bab7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/homework/models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  m.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n",
            "100% 100/100 [39:23<00:00, 23.64s/it]\n",
            "\u001b[1;34m[swscaler @ 0x6327d00] \u001b[0m\u001b[0;33mWarning: data is not aligned! This can lead to a speed loss\n",
            "\u001b[0m100 frames saved to videos/mlp_planner_lighthouse.mp4 @ 20fps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m grader homework --disable_color"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbh_wASm7kGB",
        "outputId": "423990ff-b884-433b-bce4-036116d23505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public grader loaded.\n",
            "[INFO     00:00:002] MLP Planner\n",
            "/content/./homework/models.py:215: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  m.load_state_dict(torch.load(model_path, map_location=\"cpu\"))\n"
          ]
        }
      ]
    }
  ]
}